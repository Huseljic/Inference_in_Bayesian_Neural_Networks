@techreport{settles2009active,
  title={Active learning literature survey},
  author={Settles, Burr},
  year={2009},
  institution={University of Wisconsin-Madison Department of Computer Sciences}
}
@article{Geman:1984:SRG:2286442.2286617,
 author = {Geman, Stuart and Geman, Donald},
 title = {Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images},
 journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
 issue_date = {November 1984},
 volume = {6},
 number = {6},
 year = {1984},
 issn = {0162-8828},
 pages = {721--741},
 numpages = {21},
 acmid = {2286617},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 keywords = {Annealing, Gibbs distribution, MAP estimate, Markov random field, image restoration, line process, relaxation, scene modeling, spatial degradation},
} 
@article{metropolis1953equation,
  title={Equation of state calculations by fast computing machines},
  author={Metropolis, Nicholas and Rosenbluth, Arianna W and Rosenbluth, Marshall N and Teller, Augusta H and Teller, Edward},
  journal={The Journal of Chemical Physics},
  volume={21},
  number={6},
  pages={1087--1092},
  year={1953},
  publisher={AIP}
}
@article{hernandez2016black,
  title={Black-box $\alpha$-divergence minimization},
  author={Hern{\'a}ndez-Lobato, Jos{\'e} Miguel and Li, Yingzhen and Rowland, Mark and Hern{\'a}ndez-Lobato, Daniel and Bui, Thang and Turner, Richard},
  year={2016},
  publisher={International Machine Learning Society}
}
@book{amari2012differential,
  title={Differential-geometrical methods in statistics},
  author={Amari, Shun-ichi},
  volume={28},
  year={2012},
  publisher={Springer Science \& Business Media}
}
@inproceedings{minka2001expectation,
  title={Expectation propagation for approximate Bayesian inference},
  author={Minka, Thomas P},
  booktitle={Proceedings of the Seventeenth conference on Uncertainty in artificial intelligence},
  pages={362--369},
  year={2001},
  organization={Morgan Kaufmann Publishers Inc.}
}
@article{minka2004power,
  title={Power ep},
  author={Minka, Thomas},
  journal={Dep. Statistics, Carnegie Mellon University, Pittsburgh, PA, Tech. Rep},
  year={2004}
}
@inproceedings{li2017dropout,
  title={Dropout inference in bayesian neural networks with alpha-divergences},
  author={Li, Yingzhen and Gal, Yarin},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={2052--2061},
  year={2017},
}
@article{vgg,
  added-at = {2016-11-19T13:14:27.000+0100},
  author = {Simonyan, Karen and Zisserman, Andrew},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl = {https://www.bibsonomy.org/bibtex/20ee0434e0a70b329d5518f43f1742f7a/albinzehe},
  interhash = {4e6fa56cb7cf99400d5701543ee228de},
  intrahash = {0ee0434e0a70b329d5518f43f1742f7a},
  keywords = {cnn ma-zehe neuralnet},
  timestamp = {2016-11-19T13:14:27.000+0100},
  title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  year = 2014
}
@article{Srivastava:2014:DSW:2627435.2670313,
 author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
 title = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
 journal = {Journal of Machine Learning Research},
 issue_date = {January 2014},
 volume = {15},
 number = {1},
 year = {2014},
 issn = {1532-4435},
 pages = {1929--1958},
 numpages = {30},
 acmid = {2670313},
 keywords = {deep learning, model combination, neural networks, regularization},
} 
@article{cifar,
title= {CIFAR-10 (Canadian Institute for Advanced Research)},
journal= {},
author= {Alex Krizhevsky and Vinod Nair and Geoffrey Hinton},
year= {},
abstract= {The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. 

The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. },
keywords= {Dataset},
terms= {}
}
@article{lecun-mnisthandwrittendigit-2010,
  added-at = {2010-06-28T21:16:30.000+0200},
  author = {LeCun, Yann and Cortes, Corinna},
  biburl = {https://www.bibsonomy.org/bibtex/2935bad99fa1f65e03c25b315aa3c1032/mhwombat},
  groups = {public},
  howpublished = {http://yann.lecun.com/exdb/mnist/},
  interhash = {21b9d0558bd66279df9452562df6e6f3},
  intrahash = {935bad99fa1f65e03c25b315aa3c1032},
  keywords = {MSc _checked character_recognition mnist network neural},
  lastchecked = {2016-01-14 14:24:11},
  timestamp = {2016-07-12T19:25:30.000+0200},
  title = {{MNIST} handwritten digit database},
  username = {mhwombat},
  year = 2010
}
@article{shridhar2019comprehensive,
  title={A Comprehensive guide to Bayesian Convolutional Neural Network with Variational Inference},
  author={Shridhar, Kumar and Laumann, Felix and Liwicki, Marcus},
  year={2019}
}
@misc{kingma2013autoencoding,
  abstract = {How can we perform efficient inference and learning in directed probabilistic
models, in the presence of continuous latent variables with intractable
posterior distributions, and large datasets? We introduce a stochastic
variational inference and learning algorithm that scales to large datasets and,
under some mild differentiability conditions, even works in the intractable
case. Our contributions is two-fold. First, we show that a reparameterization
of the variational lower bound yields a lower bound estimator that can be
straightforwardly optimized using standard stochastic gradient methods. Second,
we show that for i.i.d. datasets with continuous latent variables per
datapoint, posterior inference can be made especially efficient by fitting an
approximate inference model (also called a recognition model) to the
intractable posterior using the proposed lower bound estimator. Theoretical
advantages are reflected in experimental results.},
  added-at = {2018-09-01T00:55:48.000+0200},
  author = {Kingma, Diederik P and Welling, Max},
  biburl = {https://www.bibsonomy.org/bibtex/2d5418945b5a08cf2ad018a9d593364ed/gonzalob90},
  interhash = {85731e0fbdb10b8543ea9f55301b37a5},
  intrahash = {d5418945b5a08cf2ad018a9d593364ed},
  keywords = {VAE},
  title = {Auto-Encoding Variational Bayes},
  year = 2013
}
@inproceedings{Kingma:2015:VDL:2969442.2969527,
 author = {Kingma, Diederik P. and Salimans, Tim and Welling, Max},
 title = {Variational Dropout and the Local Reparameterization Trick},
 booktitle = {Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 2},
 series = {NIPS'15},
 year = {2015},
 location = {Montreal, Canada},
 pages = {2575--2583},
 numpages = {9},
 acmid = {2969527},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
}
@incollection{Graves2011Practical,
title = {Practical Variational Inference for Neural Networks},
author = {Graves, Alex},
booktitle = {Advances in Neural Information Processing Systems 24},
pages = {2348--2356},
year = {2011},
publisher = {Curran Associates, Inc.},
}
@article{Kullback51klDivergence,
  added-at = {2010-10-31T19:59:47.000+0100},
  author = {Kullback, S. and Leibler, R. A.},
  biburl = {https://www.bibsonomy.org/bibtex/2560a5719c537c5c4a496bfebd4a21603/lee_peck},
  description = {Kullback , Leibler : On Information and Sufficiency},
  interhash = {f9d41d76a07383cca4c3a1a94c24d533},
  intrahash = {560a5719c537c5c4a496bfebd4a21603},
  journal = {Ann. Math. Statist.},
  keywords = {51 Kullback Leibler divergence kl},
  number = 1,
  pages = {79-86},
  timestamp = {2010-10-31T19:59:47.000+0100},
  title = {On Information and Sufficiency},
  volume = 22,
  year = 1951
}
@article{blei2017variational,
  title={Variational inference: A review for statisticians},
  author={Blei, David M and Kucukelbir, Alp and McAuliffe, Jon D},
  journal={Journal of the American Statistical Association},
  volume={112},
  number={518},
  pages={859--877},
  year={2017},
  publisher={Taylor \& Francis}
}
@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in Neural Information Processing systems},
  pages={1097--1105},
  year={2012}
}
@article{Rumelhart:1986we,
  added-at = {2019-05-21T10:10:49.000+0200},
  author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
  biburl = {https://www.bibsonomy.org/bibtex/2a392597c4f9cff2cd3c96c2191fa1eb6/sxkdz},
  interhash = {c354bc293fa9aa7caffc66d40a014903},
  intrahash = {a392597c4f9cff2cd3c96c2191fa1eb6},
  journal = {Nature},
  keywords = {imported},
  number = 6088,
  pages = {533--536},
  timestamp = {2019-05-21T10:10:49.000+0200},
  title = {{Learning Representations by Back-propagating Errors}},
  volume = 323,
  year = 1986
}
@book{amit1992modeling,
  title={Modeling brain function: The world of attractor neural networks},
  author={Amit, Daniel J and Amit, Daniel J},
  year={1992},
  publisher={Cambridge university press}
}
@book{HaykinNeuralNetworks,
 author = {Haykin, Simon},
 title = {Neural Networks: A Comprehensive Foundation},
 year = {1998},
 isbn = {0132733501},
 edition = {2nd},
 publisher = {Prentice Hall PTR},
 address = {Upper Saddle River, NJ, USA},
} 
@inproceedings{BlundellBBB,
 author = {Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
 title = {Weight Uncertainty in Neural Networks},
 booktitle = {Proceedings of the 32nd International Conference on Machine Learning - Volume 37},
 series = {ICML'15},
 year = {2015},
 location = {Lille, France},
 pages = {1613--1622},
 numpages = {10},
 acmid = {3045290},
} 
@Book{           bishop:2006:PRML,
  author = 	 "Christopher M. Bishop",
  title = 	 "Pattern Recognition and Machine Learning",
  publisher = 	 "Springer",
  year = 	 "2006",
}
@article{mackay1992practical,
  title={A practical Bayesian framework for backpropagation networks},
  author={MacKay, David JC},
  journal={Neural computation},
  volume={4},
  number={3},
  pages={448--472},
  year={1992},
  publisher={MIT Press}
}
@inproceedings{hernandez2015probabilistic,
  title={Probabilistic backpropagation for scalable learning of bayesian neural networks},
  author={Hern{\'a}ndez-Lobato, Jos{\'e} Miguel and Adams, Ryan},
  booktitle={International Conference on Machine Learning},
  pages={1861--1869},
  year={2015}
}
@PhdThesis{Gal2016Uncertainty,
  title={Uncertainty in Deep Learning},
  author={Gal, Yarin},
  year={2016},
  school={University of Cambridge}
}
@inproceedings{Gal2016Dropout,
 author = {Gal, Yarin and Ghahramani, Zoubin},
 title = {Dropout As a Bayesian Approximation: Representing Model Uncertainty in Deep Learning},
 booktitle = {Proceedings of the 33rd International Conference on Machine Learning - Volume 48},
 series = {ICML'16},
 year = {2016},
 location = {New York, NY, USA},
 pages = {1050--1059},
 numpages = {10},
 acmid = {3045502},
} 
@article{Gal2015Bayesian,
Author = {Yarin Gal and Zoubin Ghahramani},
Title = {Bayesian Convolutional Neural Networks with {B}ernoulli Approximate Variational Inference},
Year = {2015},
}
@inproceedings{gal2017deep,
  title={Deep bayesian active learning with image data},
  author={Gal, Yarin and Islam, Riashat and Ghahramani, Zoubin},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1183--1192},
  year={2017},
  organization={JMLR. org}
}
@phdthesis{Neal:1995:BLN:922680,
 author = {Neal, Radford M.},
 advisor = {Hinton, Geoffrey},
 title = {Bayesian Learning for Neural Networks},
 year = {1995},
 isbn = {0-612-02676-0},
 publisher = {University of Toronto},
 address = {Toronto, Ont., Canada, Canada},
} 
@InProceedings{efficient_net,
  title = 	 {{E}fficient{N}et: Rethinking Model Scaling for Convolutional Neural Networks},
  author = 	 {Tan, Mingxing and Le, Quoc},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {6105--6114},
  year = 	 {2019},
  volume = 	 {97},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/tan19a/tan19a.pdf},
}
@article{multigrain,
  author    = {Maxim Berman and
               Herv{\'{e}} J{\'{e}}gou and
               Andrea Vedaldi and
               Iasonas Kokkinos and
               Matthijs Douze},
  title     = {MultiGrain: a unified image embedding for classes and instances},
  year      = {2019},
  eprint    = {1902.05509},
  timestamp = {Tue, 21 May 2019 18:03:38 +0200},
}
@article{nlp1,
  author    = {Li Dong and
               Nan Yang and
               Wenhui Wang and
               Furu Wei and
               Xiaodong Liu and
               Yu Wang and
               Jianfeng Gao and
               Ming Zhou and
               Hsiao{-}Wuen Hon},
  title     = {Unified Language Model Pre-training for Natural Language Understanding
               and Generation},
  year      = {2019},
  timestamp = {Mon, 27 May 2019 13:15:00 +0200},
}
@article{nlp2,
  author    = {Ye Jia and
               Yu Zhang and
               Ron J. Weiss and
               Quan Wang and
               Jonathan Shen and
               Fei Ren and
               Zhifeng Chen and
               Patrick Nguyen and
               Ruoming Pang and
               Ignacio Lopez{-}Moreno and
               Yonghui Wu},
  title     = {Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech
               Synthesis},
  year      = {2018},
  timestamp = {Mon, 13 Aug 2018 16:48:47 +0200},
}
@incollection{Kendall2017Uncertainy,
title = {What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?},
author = {Kendall, Alex and Gal, Yarin},
booktitle = {Advances in Neural Information Processing Systems 30},
pages = {5574--5584},
year = {2017},
publisher = {Curran Associates, Inc.},
}
@article{car_accident,
title = "Aleatoric or epistemic? Does it matter?",
keywords = "systems, statistical dependence, ergodicity, probability distribution choice, parameter uncertainty, predictive models, epistemic, uncertainty, time-variant reliability, aleatory",
author = "{Der Kiureghian}, Armen and Ditlevsen, {Ove Dalager}",
year = "2009",
language = "English",
volume = "31",
pages = "105--112",
journal = "Structural Safety",
issn = "0167-4730",
publisher = "Elsevier B.V.",
number = "2",
}

